\section{Conclusions}

	We investigated a variety of high-dimensional imputation approaches that can deal with large numbers 
	of possible predictors in the imputation models.
	These methods have the potential to simplify the decisions social scientists have to make when defining
	which predictors to include in their imputation models.
	The methods performances in terms of estimation bias and confidence interval coverage of true parameter values were 
	compared with both synthetic and real survey data studies.

	We found that \emph{bridge}, a very popular approach to deal with large sets of predictors in the imputation models,
	is inadequate to deal with strictly high dimensional data set ups ($n < p$).
	The use of regularized regression within the MICE framework is a powerful tool to automate decisions regarding which
	variables to include in the imputation models, especially when used exclusively for model trimming (IURR).
	However, the performance of these methods comes at a computational cost that can translates to 
	prohibitive long imputation procedures.

	Finally, the use of PCA to reduce the dimensionality of the data, as a pre-processing step followed by regular 
	low-dimensional MICE imputation strategies, proved to be a fast and effective approach.
	It was especially effective in preserving relationships between variables with missing values.
	In experiments 1 and 2, it produced negligible covariance biases when all other methods did not.

	The inclusion of State-of-the-art modern regression techniques within the MICE framework has been developed 
	in recent years allowing imputers to include all available predictors in imputation models.
	These methods had not been compared among themselves and not all of them had been tested with general multivariate 
	missing data patterns.
	Our research fills this gap and provides initial insights into applying such methods in social research.
	[MAKE THIS PARAGRAPH BETTER, ON THE LINE OF ZHAO LONG CONCLUSION]

\paragraph{Limitations and future directions}

	As this work aimed at comparing current implementations of different methods, some limitations
	to the scope of the simulation and resampling studies were imposed by the current state of development of 
	the different methods.
	For example, both IURR/DURR and MI-PCA allow imputation of any type of data:
	IURR and DURR have been developed for categorical data imputation \citep{dengEtAl:2016},
	and MI-PCA can be performed with any standard imputation model for categorical data.
	However, blasso has not been formally developed for multi-categorical imputation target variables yet, 
	which limited the study to working with missing values on variables that are either continuous in nature 
	or usually considered as such in practice.
	In the resampling study, IURR, DURR and MI-PCA could have performed better had they been used in their
	ordered categorical data implementations.
	However,to maintain a fair comparison with blasso, they were implemented with the assumption that the imputed 
	variables are continuous and normally distributed.

	Furthermore, in real survey data, the missing data mechanism might be non-linear, which would require
	including interactions between auxiliary variables and polynomial terms in the imputation models,
	and would lead to increase dimensionality even more.
	This factor was not part of the scope of this project. 
	However, all of the high-dimensional imputation methods considered have great potential to allow the 
	specification of much more complex response mechanisms.

	Both IURR and DURR could have been implemented with different types of penalty formulations.
	Along with the traditional lasso penalty, \cite{zhaoLong:2016} used elastic net penalty \citep{zouHastie:2005} 
	and adaptive lasso \citep{zou:2006}.
	Although no substantial performance differences between penalty specifications for IURR and DURR emerged 
	from the joint work of \cite{zhaoLong:2016} and \cite{dengEtAl:2016}, the impact of different types of 
	regularized regression was not investigated in the present study. 

	MI-PCA specification required making a decision on the number of components to extract from the auxiliary 
	variables.
	In this study, we decided to retain the first components that explained 50\% of the total variance in the 
	auxiliary variables.
	However, this decision is arbitrary and its effect on the imputation accuracy remains an interesting 
	topic for future research.


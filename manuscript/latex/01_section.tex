\section{Introduction}

%\paragraph{(Frame the problem)}

Todayâ€™s social, behavioral and medical scientists have access to large multidimensional datasets that can be
used to investigate the complex relationships between social, psychological and biological factors in 
shaping individual and societal outcomes.
Large social science datasets, such as the World Values Survey, or the European Values Study (EVS), 
are easily available to researchers and initiatives have been undertaken to link and extend these datasets 
into a system of linked open data.
Making use of the full potential of these data sets requires dealing with the crucial problem of multivariate
missing data.

Rubin's Multiple Imputation (MI) approach \citep{rubin:1987} was developed to specifically address the issue of missing 
responses in surveys.
MI is a three-step process that entails an imputation, analysis, and pooling phase.
The fundamental idea of the imputation phase is to replace each missing data point with $m$ plausible values sampled from 
their posterior predictive distributions given the observed data.
This procedure leads to the definition of $m$ complete versions of the original data that can be analyzed separately 
using standard complete-data analysis models (analysis phase).
Finally, the $m$ estimates of any parameter of interest can be pooled following Rubin's rules \citep{rubin:1987} 
(pooling phase).

Since Rubin's seminal work, two main strategies have become popular for multiple imputation of multivariate 
missing data: joint modelling (JM) \citep[ch. 4]{schafer:1997} and full conditional specification (FCS), also known 
as Multiple Imputation by Chained Equation (MICE).
\citep{vanBuurenEtAl:2006}.
The first one relies on defining a multivariate distribution for the missing data, deriving conditional
distributions for each missing data pattern, and obtaining samples by means of a Markov Chain Monte Carlo algorithm.
The second method defines conditional densities for each incomplete variable and performs iterative imputations on 
a variable-by-variable basis.

When applied to large multidimensional datasets, there are at least two reasons to prefer the FCS approach over the JM.
First of all, the complexity of the FCS method increases with the number of variables with missing values, while the complexity
of the JM approach increases with the number of missing data patterns that manifest in a dataset.
Given a number of $p$ variables, the FCS approach needs to specify at most $p$ imputation models, while the JM 
approach requires an imputation model for each missing data pattern.
Furthermore, the FCS approach allows a great level of flexibility to accommodate the peculiarities of surveys and 
other large multidimensional datasets.
FCS can easily accommodate for the different distributions of variables and it can preserve unique features in the data,
such as skip patterns or variables interactions.

Both the JM and the FCS approaches rely on the crucial \emph{missing at random} (MAR) assumption.
Meeting this assumption requires specifying imputation models for the MI procedure that include all observed
variables that are correlates of missingness.
Omitting from the imputation models an observed predictor related to both the missingness and the imputed variables 
creates a \emph{missing not at random} (MNAR) problem.
MI under MNAR leads to substantial bias in parameter estimation in the analysis and pooling phases, and 
invalidates hypothesis testing involving the imputed variables.

As a result, when it comes to defining the set of auxiliary variables for the imputation models within an MI procedure, 
an inclusive strategy (i.e. including numerous auxiliary variables) is generally preferred to restrictive approach 
(i.e. including few or no auxiliary variables).
An inclusive approach reduces the chances of omitting important correlates of missingness, making the MAR assumption 
more plausible.
Furthermore, the inclusive strategy has been shown to reduce estimation bias and increase efficiency \citep{collinsEtAl:2001},
as well as reducing the chances of specifying uncongenial imputation and analysis models \citep{meng:1994}.

Specifying the imputation models for a FCS MI procedure remains one of the most challenging steps in dealing
with missing values for large multidimensional data sets.
In practice, the inclusive strategy faces identification and computational limitations.
One serious risk of an inclusive strategy is the occurrence of singular matrices within the imputation algorithm.
When data is high-dimensional (i.e. the number of recorded units $n$ is not substantially larger than the number of recorded 
variables $p$) or afflicted by high collinearity (i.e. one or more of the variables is equal to a linear 
combination of the others) the data covariance matrix is singular.
Singular matrices are not invertible, an operation that is fundamental in the estimation of the imputation 
models in any parametric imputation procedure.
As a result, the possible high dimensionality of the observed data matrix, resulting from an inclusive strategy, 
can prevent a straightforward application of MI algorithms, such as MICE \citep{vanBuuren:2012}, or force
researchers to make arbitrary choices regarding which variables to use.

Recent developments in high-dimensional data multiple imputation techniques represent interesting 
opportunities to embrace an inclusive strategy, without facing its downsides.
Some statisticians and machine learning experts have focused on high-dimensional single imputation methods in an effort to 
improve the accuracy of individual imputations \citep[e.g.][]{kimEtAl:2005, stekhovenBuhlmann:2011, d'ambrosioEtAl:2012}. 
However, the main task of social scientists is to make inference about a population based on a sample of observed 
data points, and single imputation is simply inadequate for this purpose: it does not provide statistically valid 
inference \citep{rubin:1996}.
The concept of statistical validity as defined by \citep{rubin:1996} is meant to capture two features of 
estimation.
First, the point estimate of a parameter of interest must be unbiased, and second, the actual 
confidence interval coverage (CIC) must be equal or greater than nominal coverage.
Single imputation strategies might meet the first requirement, but cannot meet the second as they 
do not take into account the uncertainty regarding the imputed values.
Multiple Imputation, on the other hand, was designed to provide statistically valid inference and therefore is 
more suitable for social scientific research.

The combination of MI with high-dimensional prediction models has been directly tackled by algorithms combining 
full conditional specification of imputation models with shrinkage methods \citep{zhaoLong:2016, dengEtAl:2016},
but their application has been studied only for biomedical sciences.
Other researchers have proposed FCS strategies using dimensionality reduction to avoid the obstacles of an inclusive
strategy in high-dimensional data imputation.
However, these solutions were either limited to the Joint Modeling approach \citep{songBelin:2004}, 
or tested exclusively on particularly low-dimensional settings \citep{howardEtAl:2015}.
Finally, tree-based FCS strategies have the potential to overcome the limitations of inclusive strategies.
The non-parametric nature of decision trees bypasses the identification issues most parametric methods face
in high-dimensional contexts.
However, these methods have been proposed to deal with other issues, such as imputation in the presence
of interaction effects \citep{dooveEtAl:2014}, or have been tested exclusively on biomedical datasets 
\citep{shahEtAl:2014}.
%
\paragraph{Scope}
The inclusion of shrinkage methods, principal component analysis and non-parametric decision trees within the FCS framework 
have the potential of simplifying the decisions social scientists need to make when dealing with missing values.
The lack of comparative research on these methods performances makes it difficult for social scientiest working with large
multidimensional data sets to decide which imputation method to adopt.
With this article, we provide a comparison of these state-of-the-art high-dimensional imputation algorithms.
We compared the imputation methods based on the statistical validity of the complete-data analyses they allow to perform.
The comparison was based on two simulation studies and a resampling study using real survey data.
%
\paragraph{Outline}
This paper is organized as follows. 
Section 2 presents the general MICE framework, how the high-dimensional MI methods fit within it, and some
single data missing data strategies considered for reference.
Section 3 presents the two simulation studies, their design and results.
Section 4 presents the resampling study performed on real survey data.
Section 5 discusses the implication of the results of the simulation and resampling studies.
Finally, section 6 provides concluding remarks, a description of the limitations of the study, and  
future research directions we want to take.

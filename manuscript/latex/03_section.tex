\maketitle
\section{Simulation Studies}

The simulation study was broken up in two separate experiments: (1) the first was used to define a baseline comparison 
of the methods on multivariate normal data in both high and low dimensional conditions; (2) the second was used to 
assess the performance of the methods in the presence of a latent structure, in order to reflect the fundamental
structure of social survey data.

\subsection{Methods: two simulation studies}

\paragraph{Data generations}

	In experiment 1, the $\bm{X}_{n \times p}$ data matrix was generated by drawing from the multivariate normal 
	model with a vector $\bm{\mu_0}$ of mean 0 and a covariance matrix $\bm{\Sigma}_0$ with diagonal 
	elements (variances) equal to 1. $\bm{Sigma}_0$ was used to define three blocks of variables: the 
	first five variables were highly correlated among themselves ($\rho = .6$); variables 6 to 10
	were slightly correlated with variables in block 1 and among themselves ($\rho = .3$), and all 
	the remaining $p-10$ variables were uncorrelated.

	Describe latent variable data generation for the second simulation study.

	In experiment 2, the observed data $\bm{X}_{n \times p}$ was created based on a Confirmatory
	Factor Analysis model. Values on the $p$ observed items for the $i$-th observation were obtained
	with the following measurement model:

	\begin{equation}
		\bm{x}_i = \bm{\Lambda} \bm{\xi}_{i.} + \bm{\delta}_{i.}
	\end{equation}

	where $\bm{x}_i$ is a vector of scores on each observed item for observation $i = 1, ..., n$,
	$\bm{\Lambda}$ is the matrix of factor loadings, $\bm{\xi}_{i.}$ is a vector of scores on the
	latent variables for observation $i$, and $\bm{\delta_{i.}}$ is a vector of uncorrelated multivariate 
	normal measurement errors.

	Latent scores are sampled from a multivariate normal distribution centered around an $n \times l$ 
	vector of $0s$, and a covariance matrix $\bm{\Psi}_0$, with diagonal elements equal to 1 and off-diagonal 
	elements equal to correlation between latent factors. In particular, the first 4 latent variables
	are highly correlated ($\rho = .6$), the second block of 4 latent variables are somewhat correlated 
	($\rho = .3$), while the remaining $l-8$ latent variables are uncorrelated.

	The matrix $\bm{\Lambda}$ defines a simple latent structure where items load on only 1 factor (5 items 
	for each latent variable). 
	Both the items and latent factor variance are set to 1, $var{x_i} = 1$ and $\Psi_{ii} = 1$, so that 
	the measurement error is defined as $var(\delta) = 1 - \lambda^{2} 1$. 
	Factor loadings are hence defined as standardized values that range between 0 and 1, where the first value 
	implies a lack of latent structure and the second defines items that perfectly measure the latent 
	structure.
	The exact values for the latent factors are drawn for each repetition from a uniform distribution between
	a lower and upper bound, $b_l$ and $b_u$, that are condition-specific (see below).

\paragraph{Missing data imposition}

	The nonresponse mechanism was modelled as a logit regression:

	\begin{equation} \label{eqn:rm}
		p(x_t = MISSING | X) = \bm{\Phi}(\tilde{X}\bm{\theta})
	\end{equation}

	with $x_t$ a variable target of missing data imposition, $\bm{\Phi}(\dot)$ being the logistic cumulative
	distribution function, $\bm{\tilde{X}}$ the matrix of predictors defining the missing data mechanism,
	and $\bm{\theta}$ a vector of non-trivial regression coefficients.
	
	An offsetting constant was added to $\tilde{X}\bm{\theta}$ to make observations with lower values of the 
	linear combination $\tilde{X}\bm{\theta}$ to have higher chances of having a missing value. The offsetting 
	constant was chosen to minimize the difference between a target proportion of missing values and its actual 
	value.

	In experiment 1, six variables were chosen as target of missing data imposition: three variables in the block of 
	highly correlated and 3 in the block of lowly correlated variables ($x_t$ with $t = 1,..3,6,...,8$). 
	Item nonresponse was imposed following equation (\ref{eqn:rm}) with 4 variables included in $\tilde{X}$: two fully 
	observed variables from both the high and lowly correlated group of variables ($x_r$ with $r = 4,5,9,10$).

	In experiment 2, item nonresponse was imposed on the 10 items measuring two highly correlated latent
	variables ($l = 1, 2$) via a MAR mechanism using the other two highly correlated latent variables ($l = 3, 4$) as 
	predictors in response model (\ref{eqn:rm}).

\paragraph{Analysis model(s)}

	The substantive model of interest in experiment 1 is a saturated model that estimates means,
	variances, and covariances of all the variables.

	For experiment 2, the same saturated model was fitted to obtain means, variances, and covariances on the raw
	data, and on the mean scored scales obtained by averaging values across items measuring each latent variable.
	Furthermore, we fitted a Confirmatory Factor Analysis to see how the factor scores are recovered after
	imputation.

\paragraph{Criteria}
	To compare the performance of the different imputation methods, several outcome measures were considered.

	First, we used Percent Relative Bias ($PRB$) and Standardized Bias ($SB$) to quantify the bias introduced by the imputation
	procedure.

	\begin{equation} \label{eqn:prb}
		PRB = \frac{\bar{\hat{\theta}} - \theta}{\theta} \times 100
	\end{equation}

	\begin{equation} \label{eqn:sb}
		SB =  \frac{\bar{\hat{\theta}} - \theta}{SD_{\hat{\theta}}}
	\end{equation}
	
	where $\theta$ represents the reference value (the "true" value) of the focal parameter, $\bar{\hat{\theta}}$
	represents the estimate of the focal parameter averaged over the MCMC replications, $SD_{\hat{\theta}}$
	represents the empirical standard deviation of $\theta$, and $I(.)$ is the indicator function that returns 1
	if the argument is true and 0 otherwise. 

	To assess the integrity of hypothesis testing, the Confidence Interval Coverage of the reference value
	was considered as

	\begin{equation} \label{eqn:sb}
		CIR =  \frac{ \sum_{n=1}^{R} I(\hat{\theta} \in \widehat{CI}_r ) }{R}
	\end{equation}

	where R is the total number of MCMC repetitions, $\hat{CI}_r$ is the confidence interval for the focal estimates
	in a given repetition.

	CIR below .9 are considered problematic for 95\% confidence intervals \cite[p. 52]{vanBuuren:2018}.
	Confidence interval coverage higher than .95 may indicate confidence intervals that are too wide, implying that
	the imputation method leads to more conservative inferential conclusions, and in this sense it is less worrisome 
	than lower than nominal coverage.

\paragraph{Procedure}
	Summary description of crossed conditions.
	
	To assess the statistical validity of the different imputation methods we have repeated the following steps
	500 times ($R = 500$)

	\begin{itemize}
		\item Data generation - A data matrix $\bm{X}$ is generate according to an experiment specific model
			(i.e. multivariate normal model and confirmatory factor analysis for experiment 1 and 2, 
			repsectively)
		\item Missing data imposition - Missing values are imposed on a given number of target variables
			according to the response model (\ref{eqn:rm}) described above
		\item Imputations - Each method described in section 2 to deal with missingness is used to impute 
			missing values, this includes Complete case analysis, and single and multiple imputation 
			methods.
		\item Analysis - All analysis models are fitted to the data treated with the different approaches.
			Parameters estimates are pooled across the differently imputed datasets for the MI methods.
		\item Storing - All estimates are stored to be used for the computation of the outcome measures
	\end{itemize}

	The $R$ estimates obtained with the Gold Standard approach are averaged and considered as "true" reference
	values of the parameters in the analysis models.
	The $R$ estimates obtained with all other methods are used to compute PRB, SB, and CIR as described above.

	Data generation happened based on different conditions defined by design factors specific to each experiment.
	The procedure outline above was run for each of the conditions.

	For experiment 1, two experimental factors were considered: $p$, the number of columns in the dataset, which 
	are all fed to the imputation algorithms, and the target proportion of per variable missing cases. 
	For experiment 2, the dimensionality of the data was controlled based on the number of latent variables. 
	Two values were used for this factor: 10 and 100. 
	In all conditions, 5 items were generated as measures for each latent variable, making conditions with $lv = 10$ 
	low dimensional conditions, with 50 total predictors and a constant sample size of 200 observations, and 
	conditions with $lv = 100$ high dimensional ones, with data matrices of dimensionality $200 \times 500$.
	In experiment 2, we have also varied two other factors: (1) the proportion of missing values as in experiment 1, 
	and (2) the strength of the latent structure by drawing the values of the factor loadings used to generate data
	from a range of low (between .5 and .6) or high values (between .9 and .97). Table \ref{table:kysymys} Shows a summary 
	of all conditions for the two experiments.

\begin{table}
   \begin{center}
        \begin{tabular}{ c c c c c c }
		% Column names
		\textbf{condition} & \textbf{n} & \textbf{p} & \textbf{lv} & \textbf{pm} & \textbf{$\lambda$} \\ 
		\hline

		% Group name
		\rowcolor{Gray}
 		\multicolumn{6}{c}{Experiment 1} \\
		\hline

		% Row 1
		1 & 200 & 50 & 0 & .1 & - \\
		2 & 200 & 500 & 0 & .1 & - \\
		3 & 200 & 50 & 0 & .3 & - \\
		4 & 200 & 500 & 0 & .3 & - \\
	\hline
		& & & & & \\ 

		% Group Name
		\rowcolor{Gray}
 		\multicolumn{6}{c}{Experiment 2} \\
		\hline

		1 & 200 & 50 &  10 & high & 0.1 \\
		2 & 200 & 500 & 100 & high & 0.1 \\
		3 & 200 & 50 &  10 & high & 0.3 \\
		4 & 200 & 500 & 100 & high & 0.3 \\
		5 & 200 & 50 &  10 &  low & 0.1 \\
		6 & 200 & 500 & 100 &  low & 0.1 \\
		7 & 200 & 50 &  10 &  low & 0.3 \\
		8 & 200 & 500 & 100 &  low & 0.3 \\
	\hline
        \end{tabular}
    \end{center}
\caption{Summary of conditions for experiment 1 and 2}
\label{table:kysymys}
\end{table}

	The code to Run the simulation was written in the R statistical programming language (version 4.0.3). 
	All experiments were run using a 2.6 GHz Intel Xeon(R) Gold 6126 processor, 523780 MB of Memory. The
	operating system was Windows Server 2012 R2.

	Computations were run in parallel across the available cores (between 20 and 30). Parallel computing 
	was implemented using the R package 'parallel' and to ensure replicability of the findings seeds were
	set using the method by \cite{lecuyer:2002} implemented in the R package 'rlecuyer'

\subsection{Results}

\paragraph{Bias}
	Report results of comparison in terms of estimates bias for relevant parameters

	Given concise idea of implications. Avoid higher level comparisons.
	
\paragraph{Confidence Interval Coverage}
	Report results of comparison in terms of confidence interval coverage of the "true" values of parameters 

	Given concise idea of implications. Avoid higher level comparisons.
	

